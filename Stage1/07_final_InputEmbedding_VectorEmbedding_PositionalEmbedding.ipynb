{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec13e96",
   "metadata": {},
   "source": [
    "POSITIONAL EMBEDDING ( ENCODING WORD POSITIONS )\n",
    "\n",
    "We now consider more realistic and useful embedding sizes and encode the input tokens into 256-dimensional vector,\n",
    "this is smaller than the original GPT-3 used ( in GPT3, the embedding size is 12,228 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "884f66e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from import-ipynb) (8.32.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from IPython->import-ipynb) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from IPython->import-ipynb) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from IPython->import-ipynb) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from IPython->import-ipynb) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from IPython->import-ipynb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from IPython->import-ipynb) (4.12.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->import-ipynb) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->import-ipynb) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from nbformat->import-ipynb) (5.7.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\hansi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (308)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->IPython->import-ipynb) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->IPython->import-ipynb) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hansi\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->IPython->import-ipynb) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install import-ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72b36386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import torch \n",
    "import numpy as np\n",
    "#import data_loader_implementation\n",
    "from data_loader_implementation import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd985f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dims = 256\n",
    "context_window = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46ba233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of token ids : 394637\n",
      "input :  tensor([[13268,    11,   257,  1310],\n",
      "        [  257,  4197,    13,   198],\n",
      "        [  198,   270,    11,   284],\n",
      "        [11892,   553,  4504,   262],\n",
      "        [  511,   835,   832,  2750],\n",
      "        [  447,   251,   673,   531],\n",
      "        [ 1640,  1770,    13,   376],\n",
      "        [25029, 15347, 15707,   329]]) \n",
      "target :  tensor([[   11,   257,  1310, 21100],\n",
      "        [ 4197,    13,   198,   198],\n",
      "        [  270,    11,   284, 12600],\n",
      "        [  553,  4504,   262, 21120],\n",
      "        [  835,   832,  2750, 33559],\n",
      "        [  251,   673,   531,    11],\n",
      "        [ 1770,    13,   376, 10332],\n",
      "        [15347, 15707,   329,   198]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"./fiction_stories.txt\", \"r\", encoding=\"utf-8\") as f :\n",
    "    raw_text = f.read()\n",
    "\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dims)\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=context_window, stride=context_window, num_worker=0, drop_last=True)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch_input, target = next(data_iter)\n",
    "print(\"input : \", first_batch_input, \"\\ntarget : \", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292659b",
   "metadata": {},
   "source": [
    "As we can see, the token ID tensor is 8x4 dimensional, meaning that the \n",
    "data batch consists of 8 text samples with 4 tokens each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7092aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "embedding_vectors = embedding_layer(first_batch_input)\n",
    "print(embedding_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f731cbf",
   "metadata": {},
   "source": [
    "\n",
    "For a GPT model's absolute embedding approach, we just need to create another embedding layer that has same dimension\n",
    "So create another embedding layer for position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b990820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "postional_embedding_layer = torch.nn.Embedding(context_window, output_dims)\n",
    "print(postional_embedding_layer.weight.shape)\n",
    "# print(postional_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99090d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = postional_embedding_layer(torch.arange(context_window))\n",
    "print(pos_embeddings.shape)\n",
    "# print(pos_embeddings)\n",
    "\n",
    "# for input in first_batch_input:\n",
    "#     final_input = input + pos_embeddings\n",
    "# \n",
    "# \n",
    "# \n",
    "#    print(final_input)\n",
    "\n",
    "\n",
    "# pytorch use brodcast \n",
    "\n",
    "final_input = embedding_vectors + pos_embeddings\n",
    "print(final_input.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
